{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data generation of SIR model with Demographic Noise\n",
    "#Edited from published codes by Bury et al. (2021), Deep learning for early warning signals of tipping points, PNAS. \n",
    "#python libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mlp \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os \n",
    "import ewstools \n",
    "import random\n",
    "import sys\n",
    "\n",
    "#parameters\n",
    "dt = 0.01\n",
    "t0 = 0\n",
    "tmax = 1500\n",
    "tburn = 100                                 \n",
    "numSims = 10                         \n",
    "seed = 0                                    \n",
    "\n",
    "dt2 = 1                                      \n",
    "rw = 0.25                                    \n",
    "span=0.2                                     \n",
    "lags = [1]                                 \n",
    "ews = ['var','ac']\n",
    "\n",
    "# Model\n",
    "def de_fun_S(S,I,Lambda,beta,mu):\n",
    "  return Lambda-beta*S*I-mu*S\n",
    "\n",
    "def de_fun_I(S,I,beta,alpha,mu):\n",
    "  return beta*S*I- alpha*I-mu*I\n",
    "\n",
    "\n",
    "#batches\n",
    "# count = int(sys.argv[1])  \n",
    "count = 1\n",
    "\n",
    "#model parameters\n",
    "Lambda = 100                                          \n",
    "alpha = 1\n",
    "mu = 1\n",
    "S0 = 500                                   \n",
    "I0 = 7\n",
    "\n",
    "# bifurcation point\n",
    "betabif = mu*(alpha+mu)/Lambda                   \n",
    "print(betabif)\n",
    "\n",
    "# DataFrame for each variable\n",
    "df_sims_S = pd.DataFrame([])                     \n",
    "df_sims_I = pd.DataFrame([])\n",
    "\n",
    "#arrays to store single time-series data\n",
    "t = np.arange(t0,tmax,dt)                        \n",
    "S = np.zeros(len(t))                            \n",
    "I = np.zeros(len(t))\n",
    "\n",
    "beta = np.zeros(len(t)) \n",
    "beta_intercept = []\n",
    "beta_slope = []\n",
    "tbif = np.zeros(numSims) \n",
    "\n",
    "right_intercept = betabif/2 \n",
    "mid_intercept = right_intercept/2 \n",
    "\n",
    "beta_intercept = np.random.triangular(0, mid_intercept, right_intercept, numSims)\n",
    "\n",
    "for j in range(numSims // 2):\n",
    "    left_slope = 0\n",
    "    right_slope = (betabif-beta_intercept[j])/1500\n",
    "    mid_slope = right_slope/2\n",
    "    slope = np.random.triangular(left_slope, mid_slope, right_slope)\n",
    "    beta_slope.append(slope)\n",
    "\n",
    "for j in range(numSims // 2, numSims):\n",
    "    left_slope = (betabif-beta_intercept[j])/1500\n",
    "    right_slope = (2*betabif-beta_intercept[j])/1500\n",
    "    mid_slope = right_slope/2\n",
    "    slope = np.random.triangular(left_slope, mid_slope, right_slope)\n",
    "    beta_slope.append(slope) \n",
    "\n",
    "print(beta_intercept)\n",
    "print(beta_slope)\n",
    "\n",
    " # Initialise a list to collect trajectories\n",
    "list_traj_append = []                                                            \n",
    "label_list = []\n",
    "tbif = np.zeros(numSims) \n",
    "\n",
    "# loop over simulations\n",
    "print('\\nBegin simulations \\n')\n",
    "for j in range(numSims):                \n",
    "    # noise intensity\n",
    "    sigma_S = np.random.triangular(0, 0.5, 1)                                    \n",
    "    sigma_I = np.random.triangular(0, 0.5, 1)\n",
    "    \n",
    "    beta0 = beta_intercept[j]\n",
    "    beta1 = beta_slope[j]\n",
    "    beta = np.zeros(len(t))\n",
    "\n",
    "    for k in range(len(t)): \n",
    "        beta[k] = beta0 + t[k]*beta1\n",
    "\n",
    "    beta = pd.Series(beta, index=t) \n",
    "    \n",
    "    # Time at which bifurcation occurs; we set bifurcation point at 1500 for null simulations\n",
    "    if betabif <= beta.iloc[len(t)-1]:\n",
    "        tbif[j] = beta[beta > betabif].index[1] \n",
    "    else:\n",
    "        tbif[j] = 1500\n",
    "    print(tbif)\n",
    "    \n",
    "    # Create brownian increments (s.d. sqrt(dt))\n",
    "    dW_S_burn = np.random.normal(loc=0, scale=sigma_S*np.sqrt(dt), size = int(tburn/dt))   \n",
    "    dW_S = np.random.normal(loc=0, scale=sigma_S*np.sqrt(dt), size = len(t))\n",
    "    \n",
    "    dW_I_burn = np.random.normal(loc=0, scale=sigma_I*np.sqrt(dt), size = int(tburn/dt))\n",
    "    dW_I = np.random.normal(loc=0, scale=sigma_I*np.sqrt(dt), size = len(t))\n",
    "    \n",
    "    # Run burn-in period\n",
    "    for i in range(int(tburn/dt)):                                              \n",
    "        S0 = S0 + de_fun_S(S0,I0,Lambda,beta[0],mu)*dt + dW_S_burn[i]            \n",
    "        if np.isnan(S0):\n",
    "            S0 = random.uniform(0, 500)\n",
    "        I0 = I0 + de_fun_I(S0,I0,beta[0],alpha,mu)*dt + dW_I_burn[i]\n",
    "        if np.isnan(I0): \n",
    "            I0 = random.uniform(0, 0.5)\n",
    "    \n",
    "    #if intial infected less than 0.1; set random initial between (0.1, 1)        \n",
    "    if I0 < 0.1 :\n",
    "        I0 = random.uniform(0.1 , 1)\n",
    "        \n",
    "    # Initial condition post burn-in period\n",
    "    S[0]=S0\n",
    "    I[0]=I0\n",
    "    \n",
    "    # Run simulation\n",
    "    for i in range(len(t)-1):                                                     \n",
    "        a = Lambda + beta.iloc[i]*S[i]*I[i] + mu*S[i]\n",
    "        b = -beta.iloc[i]*S[i]*I[i]\n",
    "        c = beta.iloc[i]*S[i]*I[i] + alpha*I[i] + mu*I[i]\n",
    "        d = np.sqrt(a*c-b**2)\n",
    "        e = np.sqrt(a+c+2*d)\n",
    "        S[i+1] = S[i] + de_fun_S(S[i],I[i],Lambda,beta.iloc[i],mu)*dt + ((a+d)/e)*dW_S[i] + (b/e)*dW_I[i]    \n",
    "        I[i+1] = I[i] + de_fun_I(S[i],I[i], beta.iloc[i],alpha,mu)*dt + (b/e)*dW_S[i] + ((c+d)/e)*dW_I[i]\n",
    "        # make sure that state variable remains >= 0\n",
    "        if S[i+1] < 0:                                                                                      \n",
    "            S[i+1] = 0\n",
    "        if I[i+1] < 0:\n",
    "            I[i+1] = random.uniform(0.1 , 1)\n",
    "    # Store series data in a temporary DataFrame\n",
    "    data = {'tsid': (j+1)*np.ones(len(t)),                                       \n",
    "                'Time': t,\n",
    "                'S': S,\n",
    "                'I': I}\n",
    "    df_temp = pd.DataFrame(data)                                                 \n",
    "    list_traj_append.append(df_temp)     \n",
    "    \n",
    "    if betabif <= beta.iloc[len(t)-1]:\n",
    "        df_label = pd.DataFrame([1])\n",
    "    else:\n",
    "        df_label = pd.DataFrame([0])\n",
    "    \n",
    "    label_list.append(df_label)\n",
    "    print('Simulation '+str(j+1)+' complete')\n",
    "    \n",
    "    beta0 = []\n",
    "    beta1 = []\n",
    "\n",
    "label = pd.concat(label_list, ignore_index=True)\n",
    "df_traj = pd.concat(list_traj_append)                                            \n",
    "df_traj.set_index(['tsid','Time'], inplace=True)\n",
    "\n",
    "# Compute EWS, variance and lag-1 AC for each simulation\n",
    "#---------------------\n",
    "\n",
    "# Filter time-series to have time-spacing dt2\n",
    "df_traj_filt = df_traj.loc[::int(dt2/dt)]      \n",
    "\n",
    "# set up a list to store output dataframes from ews_compute- we will concatenate them at the end\n",
    "appended_ews = []\n",
    "appended_pspec = []\n",
    "\n",
    "# loop through realisation number\n",
    "print('\\nBegin EWS computation\\n')\n",
    "for i in range(numSims):\n",
    "    # loop through variable\n",
    "    for var in ['S','I']:\n",
    "      ews_dic = ewstools.core.TimeSeries(df_traj_filt.loc[i+1][var], \n",
    "                                          transition=tbif[i])\n",
    "      \n",
    "      ews_dic.detrend(method='Lowess', span=span)                                \n",
    "      ews_dic.compute_auto(rolling_window=rw, lag=1)                             \n",
    "      ews_dic.compute_var(rolling_window=rw)                                     \n",
    "\n",
    "      # The DataFrame of EWS\n",
    "      z1 = ews_dic.state                                                         \n",
    "      z2 = ews_dic.ews                                                           \n",
    "      df_ews_temp = pd.concat([z1, z2], axis=1)                                 \n",
    "    \n",
    "      # Include a column in the DataFrames for realisation number and variable\n",
    "      df_ews_temp['tsid'] = i+1\n",
    "      df_ews_temp['Variable'] = var\n",
    "    \n",
    "      # Add DataFrames to list\n",
    "      appended_ews.append(df_ews_temp)\n",
    "        \n",
    "    # Print status every realisation\n",
    "    if np.remainder(i+1,1)==0:\n",
    "      print('EWS for realisation '+str(i+1)+' complete')\n",
    "\n",
    "# Concatenate EWS DataFrames\n",
    "df_ews = pd.concat(appended_ews).reset_index().set_index(['tsid','Variable','Time'])\n",
    "\n",
    "#Export individual resids files \n",
    "existing_simulation_number = 0\n",
    "sim_index = (count-1)*numSims+existing_simulation_number\n",
    "\n",
    "if not os.path.exists('../Training_Data/data_train_DemNoise/output_sims_batch{}'.format(count)):\n",
    "    os.makedirs('../Training_Data/data_train_DemNoise/output_sims_batch{}'.format(count)) \n",
    "\n",
    "if not os.path.exists('../Training_Data/data_train_DemNoise/output_resids_batch{}'.format(count)):\n",
    "    os.makedirs('../Training_Data/data_train_DemNoise/output_resids_batch{}'.format(count))\n",
    "\n",
    "for i in np.arange(numSims)+1:\n",
    "    Ind_tseries = df_ews.sort_index().loc[i,'I'].reset_index()[['Time','state']]\n",
    "    tseries_rename = Ind_tseries.rename(columns={'Time': 'Time', 'state': 'I'})\n",
    "    filepath='../Training_Data/data_train_DemNoise/output_sims_batch{}/tseries{}.csv'.format(count,sim_index+i)\n",
    "    tseries_rename.to_csv(filepath,\n",
    "                     index=False)    \n",
    "    df_resids = df_ews.sort_index().loc[i,'I'].reset_index()[['Time','residuals']]\n",
    "    filepath='../Training_Data/data_train_DemNoise/output_resids_batch{}/resids{}.csv'.format(count, sim_index+i)\n",
    "    df_resids.to_csv(filepath,\n",
    "                     index=False)\n",
    "\n",
    "if not os.path.exists('../Training_Data/data_train_DemNoise/output_labels'):\n",
    "    os.makedirs('../Training_Data/data_train_DemNoise/output_labels')\n",
    "    \n",
    "#label_indv\n",
    "filepath = '../Training_Data/data_train_DemNoise/output_labels/label_batch{}.csv'.format(count)\n",
    "label.to_csv(filepath,\n",
    "            header=False, index=False) \n",
    "\n",
    "#store bifurcation_point\n",
    "pd.DataFrame(tbif).to_csv('../Training_Data/data_train_DemNoise/output_labels/bifurcation_points_batch{}.csv'.format(count), header=False, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
